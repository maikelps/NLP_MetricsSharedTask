{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bc20f4",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>MDSAA TEXT MINING 2020-2021</h1>\n",
    "    <h2>MACHINE TRANSLATION METRICS</h2>\n",
    "    <p style=\"text-align:center\">David Sotto-Mayor Machado (m20201023@novaims.unl.pt), Maikel Sousa (m20200735@novaims.unl.pt), Catarina Moreira (m20201034@novaims.unl.pt)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40380aed",
   "metadata": {},
   "source": [
    "<h2>Import Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5543fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maike\\Anaconda3\\envs\\TM\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, time, gzip, zlib, logging, transformers, urllib.request, shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from comet.models import download_model\n",
    "import jieba.posseg as pseg\n",
    "import comet\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "from tqdm.notebook import tqdm\n",
    "#from bert_score import score\n",
    "#from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "from stopwordsiso import stopwords as swordsiso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "#from bert_score import score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display_html \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from zipfile import *\n",
    "import platform\n",
    "#from bleurt import score\n",
    "#import bleurt\n",
    "import jieba\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f41e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e80417",
   "metadata": {},
   "source": [
    "<h2>Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21df17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text_list, stop, lemmatize, stemmer):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in range(len(text_list)): #create the bars\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        if isinstance(text, str):\n",
    "            text = text.lower()\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        if isinstance(text, str):\n",
    "            text = \" \".join([BeautifulSoup(word).get_text() for word in text.split()])\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        if isinstance(text, str):\n",
    "            text = \" \".join([word for word in text.split() if word not in stop])\n",
    "        \n",
    "        if isinstance(text, str):\n",
    "            if lemmatize:\n",
    "                text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "                \n",
    "        if isinstance(text, str):\n",
    "            if stemmer:\n",
    "                text = \" \".join(snowball_stemmer.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated,column1):\n",
    "    dataframe.update(pd.DataFrame({column1: list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6d3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_finlandes(text_list,stop, lemmatize, stemmer):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in range(len(text_list)): #create the bars\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = text.upper()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        text = re.sub(\"[^a-zA-ZǺÄÖ]\", ' ', text)\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        if lemmatize:\n",
    "            text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        if stemmer:\n",
    "            text = \" \".join(snowball_stemmer.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated,column1):\n",
    "    dataframe.update(pd.DataFrame({column1: list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2236cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chinese(text_list, stop):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in range(len(text_list)): #create the bars\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        text =  re.sub(\"[0-9]\", ' ', text)\n",
    "        \n",
    "        text = re.sub(\"r[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。. ？、~@#￥%……&*（）：；《）《》“”()»〔〕-]+\", \" \", text.encode().decode(\"utf8\"))\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated,column1):\n",
    "    dataframe.update(pd.DataFrame({column1: list_updated}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04ded1",
   "metadata": {},
   "source": [
    "<h2>Import Corpora</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aecaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 6 \u001b[0mcorpora imported.\n"
     ]
    }
   ],
   "source": [
    "#To import all the corpus csv files\n",
    "folder='testset'\n",
    "corpus = os.listdir(folder)\n",
    "#corpus.remove('.DS_Store')\n",
    "\n",
    "filename = 'scores.csv'\n",
    "corpora=[]\n",
    "\n",
    "for sub in corpus:\n",
    "    corpora.append(pd.read_csv('{}/{}/{}'.format(folder,sub,filename)))\n",
    "        \n",
    "print('\\033[1m',len(corpora),'\\033[0mcorpora imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0156bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To drop rows with missing translations or references\n",
    "for i in range(len(corpus)):\n",
    "    corpora[i].drop(corpora[i][corpora[i][\"reference\"] == \".\"].index, inplace=True)\n",
    "    corpora[i].drop(corpora[i][corpora[i][\"translation\"] == \".\"].index, inplace=True)\n",
    "    corpora[i].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68aa64d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cs-en', 'de-en', 'en-fi', 'en-zh', 'ru-en', 'zh-en']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To list the different translation language pairs\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5658b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csen = 0\n",
    "deen = 1\n",
    "enfi = 2\n",
    "enzh = 3\n",
    "ruen = 4\n",
    "zhen = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac60a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Památník, důstojné pietní místo, stojí vůlí dě...</td>\n",
       "      <td>The monument, a dignified piecemeal place, sta...</td>\n",
       "      <td>The memorial, a solemn place of commemoration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pracovník centra Čang Č-čung sdělil agentuře N...</td>\n",
       "      <td>Centre worker Zhang Zu-chung told the New Chin...</td>\n",
       "      <td>Centre worker Chang Chi-Chung told New China t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veterináři nicméně odeberou namátkové vzorky v...</td>\n",
       "      <td>However, veterinarians take random samples of ...</td>\n",
       "      <td>However, veterinarians are taking samples of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uživatel @TheePharoah jí neustále retweetoval ...</td>\n",
       "      <td>User @ TheePharoah constantly retweeted her po...</td>\n",
       "      <td>A user with the handle @TheePharoah was being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lucii bylo tehdy pouhých 19 let a rozhodně net...</td>\n",
       "      <td>Lucia was only 19 at the time and certainly ha...</td>\n",
       "      <td>At that time, Lucie was only 19 years old, and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Památník, důstojné pietní místo, stojí vůlí dě...   \n",
       "1  Pracovník centra Čang Č-čung sdělil agentuře N...   \n",
       "2  Veterináři nicméně odeberou namátkové vzorky v...   \n",
       "3  Uživatel @TheePharoah jí neustále retweetoval ...   \n",
       "4  Lucii bylo tehdy pouhých 19 let a rozhodně net...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The monument, a dignified piecemeal place, sta...   \n",
       "1  Centre worker Zhang Zu-chung told the New Chin...   \n",
       "2  However, veterinarians take random samples of ...   \n",
       "3  User @ TheePharoah constantly retweeted her po...   \n",
       "4  Lucia was only 19 at the time and certainly ha...   \n",
       "\n",
       "                                         translation  \n",
       "0  The memorial, a solemn place of commemoration,...  \n",
       "1  Centre worker Chang Chi-Chung told New China t...  \n",
       "2  However, veterinarians are taking samples of e...  \n",
       "3  A user with the handle @TheePharoah was being ...  \n",
       "4  At that time, Lucie was only 19 years old, and...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify one of the corpus\n",
    "corpora[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7038ea9",
   "metadata": {},
   "source": [
    "<h2>Pre-processing Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c3f65",
   "metadata": {},
   "source": [
    "As we know, one importante step before starting our experiments is to divide the corpora in training and test sets. However, this corpora is already divided and the corpora that is given to us is the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e467cfe",
   "metadata": {},
   "source": [
    "### Corpus inspection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cb0a4",
   "metadata": {},
   "source": [
    "Here, we are going to look into our data, understand it and think how to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3880aca",
   "metadata": {},
   "source": [
    "###### Check the training set of each corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92831199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Památník, důstojné pietní místo, stojí vůlí dě...</td>\n",
       "      <td>The monument, a dignified piecemeal place, sta...</td>\n",
       "      <td>The memorial, a solemn place of commemoration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pracovník centra Čang Č-čung sdělil agentuře N...</td>\n",
       "      <td>Centre worker Zhang Zu-chung told the New Chin...</td>\n",
       "      <td>Centre worker Chang Chi-Chung told New China t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veterináři nicméně odeberou namátkové vzorky v...</td>\n",
       "      <td>However, veterinarians take random samples of ...</td>\n",
       "      <td>However, veterinarians are taking samples of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uživatel @TheePharoah jí neustále retweetoval ...</td>\n",
       "      <td>User @ TheePharoah constantly retweeted her po...</td>\n",
       "      <td>A user with the handle @TheePharoah was being ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lucii bylo tehdy pouhých 19 let a rozhodně net...</td>\n",
       "      <td>Lucia was only 19 at the time and certainly ha...</td>\n",
       "      <td>At that time, Lucie was only 19 years old, and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Památník, důstojné pietní místo, stojí vůlí dě...   \n",
       "1  Pracovník centra Čang Č-čung sdělil agentuře N...   \n",
       "2  Veterináři nicméně odeberou namátkové vzorky v...   \n",
       "3  Uživatel @TheePharoah jí neustále retweetoval ...   \n",
       "4  Lucii bylo tehdy pouhých 19 let a rozhodně net...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The monument, a dignified piecemeal place, sta...   \n",
       "1  Centre worker Zhang Zu-chung told the New Chin...   \n",
       "2  However, veterinarians take random samples of ...   \n",
       "3  User @ TheePharoah constantly retweeted her po...   \n",
       "4  Lucia was only 19 at the time and certainly ha...   \n",
       "\n",
       "                                         translation  \n",
       "0  The memorial, a solemn place of commemoration,...  \n",
       "1  Centre worker Chang Chi-Chung told New China t...  \n",
       "2  However, veterinarians are taking samples of e...  \n",
       "3  A user with the handle @TheePharoah was being ...  \n",
       "4  At that time, Lucie was only 19 years old, and...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the first corpora\n",
    "corpora[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6ff781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das Publikum ist fast gleichmäßig zwischen Sch...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Du kannst ihre Energie durch den Bildschirm sp...</td>\n",
       "      <td>You can feel their energy through the screen. \"\"</td>\n",
       "      <td>You can feel her energy through the screen.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Da die Adresse unbekannt ist, wird die Mithilf...</td>\n",
       "      <td>As the address is unknown, the help of the pop...</td>\n",
       "      <td>As the address is unknown, the assistance of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal-Manager Arsene Wenger, dessen Verein i...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Landwirtschaftsminister im Interview - Wie sch...</td>\n",
       "      <td>Agriculture Minister in the interview - How do...</td>\n",
       "      <td>Minister of Agriculture in interview – How do ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Das Publikum ist fast gleichmäßig zwischen Sch...   \n",
       "1  Du kannst ihre Energie durch den Bildschirm sp...   \n",
       "2  Da die Adresse unbekannt ist, wird die Mithilf...   \n",
       "3  Arsenal-Manager Arsene Wenger, dessen Verein i...   \n",
       "4  Landwirtschaftsminister im Interview - Wie sch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The audience is almost evenly split between bl...   \n",
       "1   You can feel their energy through the screen. \"\"   \n",
       "2  As the address is unknown, the help of the pop...   \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...   \n",
       "4  Agriculture Minister in the interview - How do...   \n",
       "\n",
       "                                         translation  \n",
       "0  The audience is almost evenly split between bl...  \n",
       "1       You can feel her energy through the screen.\"  \n",
       "2  As the address is unknown, the assistance of t...  \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...  \n",
       "4  Minister of Agriculture in interview – How do ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the second corpora\n",
    "corpora[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d046dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One local resident who did not wish to be name...</td>\n",
       "      <td>Eräs paikallinen asukas, joka ei halunnut nime...</td>\n",
       "      <td>Toisen nimettömänä pysyttelevän asukkaan mukaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still, she clings to a chant she's committed t...</td>\n",
       "      <td>Silti hän takertuu chant hän on sitoutunut mui...</td>\n",
       "      <td>Silti hän luottaa edelleen iskulauseeseen, jon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't want to be asked, 'What were you doing...</td>\n",
       "      <td>En halua, että minulta kysytään: \"Mitä te teit...</td>\n",
       "      <td>En halua, että kenenkään tarvitsee kysyä minul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I wouldn't say it was a lie – that's a pretty...</td>\n",
       "      <td>\"En sanoisi, että se oli valhe - se on aika ro...</td>\n",
       "      <td>En sanoisi, että se oli valhe, se on aika kova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kari Kola took part in the opening ceremony of...</td>\n",
       "      <td>Kari Kola osallistui valon vuoden avajaisiin v...</td>\n",
       "      <td>Kari Kola oli mukana Valon teemavuoden avajais...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  One local resident who did not wish to be name...   \n",
       "1  Still, she clings to a chant she's committed t...   \n",
       "2  I don't want to be asked, 'What were you doing...   \n",
       "3  \"I wouldn't say it was a lie – that's a pretty...   \n",
       "4  Kari Kola took part in the opening ceremony of...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Eräs paikallinen asukas, joka ei halunnut nime...   \n",
       "1  Silti hän takertuu chant hän on sitoutunut mui...   \n",
       "2  En halua, että minulta kysytään: \"Mitä te teit...   \n",
       "3  \"En sanoisi, että se oli valhe - se on aika ro...   \n",
       "4  Kari Kola osallistui valon vuoden avajaisiin v...   \n",
       "\n",
       "                                         translation  \n",
       "0  Toisen nimettömänä pysyttelevän asukkaan mukaa...  \n",
       "1  Silti hän luottaa edelleen iskulauseeseen, jon...  \n",
       "2  En halua, että kenenkään tarvitsee kysyä minul...  \n",
       "3  En sanoisi, että se oli valhe, se on aika kova...  \n",
       "4  Kari Kola oli mukana Valon teemavuoden avajais...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the third corpora\n",
    "corpora[2][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae83e6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The future and the destinies of the citizens o...</td>\n",
       "      <td>世界上每个国家公民的未来和命运日益联系在一起。</td>\n",
       "      <td>世界各国人民前途命运越来越紧密地联系在一起。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After all that hard work, the finished result ...</td>\n",
       "      <td>经过那么多的努力，最终的结果现在已经可以揭晓了。</td>\n",
       "      <td>经过这么艰辛的工作，最终的结果现在才得以公布。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Author: researcher of Suning Institute of Fina...</td>\n",
       "      <td>作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The Great Wall” tells the story of a Chinese ...</td>\n",
       "      <td>《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。</td>\n",
       "      <td>《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our comrades from the Political Bureau should ...</td>\n",
       "      <td>政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...</td>\n",
       "      <td>中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The future and the destinies of the citizens o...   \n",
       "1  After all that hard work, the finished result ...   \n",
       "2  Author: researcher of Suning Institute of Fina...   \n",
       "3  “The Great Wall” tells the story of a Chinese ...   \n",
       "4  Our comrades from the Political Bureau should ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            世界上每个国家公民的未来和命运日益联系在一起。   \n",
       "1                           经过那么多的努力，最终的结果现在已经可以揭晓了。   \n",
       "2                        作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。   \n",
       "3          《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。   \n",
       "4  政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...   \n",
       "\n",
       "                                         translation  \n",
       "0                             世界各国人民前途命运越来越紧密地联系在一起。  \n",
       "1                            经过这么艰辛的工作，最终的结果现在才得以公布。  \n",
       "2                      作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。  \n",
       "3  《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。  \n",
       "4  中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the fourth corpora\n",
    "corpora[3][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f4569a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Через полчаса обуглившийся клубень достают и п...</td>\n",
       "      <td>After half an hour, the charred tuber is taken...</td>\n",
       "      <td>After half-an-hour, the charred tuber is retri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Здесь никто не думает отменять смертную казнь,...</td>\n",
       "      <td>Here, no one thinks to abolish the death penal...</td>\n",
       "      <td>Here, no one is concerned with abolishing the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собеседники \"Известий\" в ОНФ отмечают, что док...</td>\n",
       "      <td>The interlocutors of\" Izvestiya \"in the onf no...</td>\n",
       "      <td>Izvestia’s sources in the ONF note that the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>На древней Венере могли существовать океаны.</td>\n",
       "      <td>On the ancient Venus could exist in the oceans.</td>\n",
       "      <td>Oceans could have existed on ancient Venus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>До этого момента убийства оставались лишь исто...</td>\n",
       "      <td>Up to this point, the murders were just a stor...</td>\n",
       "      <td>Up until this point, the murders have remained...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Через полчаса обуглившийся клубень достают и п...   \n",
       "1  Здесь никто не думает отменять смертную казнь,...   \n",
       "2  Собеседники \"Известий\" в ОНФ отмечают, что док...   \n",
       "3       На древней Венере могли существовать океаны.   \n",
       "4  До этого момента убийства оставались лишь исто...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  After half an hour, the charred tuber is taken...   \n",
       "1  Here, no one thinks to abolish the death penal...   \n",
       "2  The interlocutors of\" Izvestiya \"in the onf no...   \n",
       "3    On the ancient Venus could exist in the oceans.   \n",
       "4  Up to this point, the murders were just a stor...   \n",
       "\n",
       "                                         translation  \n",
       "0  After half-an-hour, the charred tuber is retri...  \n",
       "1  Here, no one is concerned with abolishing the ...  \n",
       "2  Izvestia’s sources in the ONF note that the re...  \n",
       "3        Oceans could have existed on ancient Venus.  \n",
       "4  Up until this point, the murders have remained...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the fifth corpora\n",
    "corpora[4][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ab6b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>已经批准筹建的，暂停批准开业</td>\n",
       "      <td>Where the preparation has been approved, the a...</td>\n",
       "      <td>Approval of opening on these establishments wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>王丰源在首发式发言中说，来美国前想找本书看看别人的经验，但他翻遍新华书店没找到关于留学美国中...</td>\n",
       "      <td>In his opening speech, Mr. Wang said he wanted...</td>\n",
       "      <td>Wang Fengyuan spoke at the launch of his new b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“如果你不致力于创造透明文化，你会失去人才，”维特拉诺说道。</td>\n",
       "      <td>\"if you're not committed to creating a culture...</td>\n",
       "      <td>\"If you're not committed to creating a culture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不过前提是多国联军先停止对也门的袭击。</td>\n",
       "      <td>The premise, however, is that the coalition fo...</td>\n",
       "      <td>However, the premise is that the multinational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“在此之前，我和前男友住在骑士桥的一个更大的房子里，”乔安妮说道。</td>\n",
       "      <td>\"before that, my ex and I lived in a bigger ho...</td>\n",
       "      <td>\"Before this, I was living with my ex in Knigh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                                     已经批准筹建的，暂停批准开业   \n",
       "1  王丰源在首发式发言中说，来美国前想找本书看看别人的经验，但他翻遍新华书店没找到关于留学美国中...   \n",
       "2                     “如果你不致力于创造透明文化，你会失去人才，”维特拉诺说道。   \n",
       "3                                不过前提是多国联军先停止对也门的袭击。   \n",
       "4                  “在此之前，我和前男友住在骑士桥的一个更大的房子里，”乔安妮说道。   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Where the preparation has been approved, the a...   \n",
       "1  In his opening speech, Mr. Wang said he wanted...   \n",
       "2  \"if you're not committed to creating a culture...   \n",
       "3  The premise, however, is that the coalition fo...   \n",
       "4  \"before that, my ex and I lived in a bigger ho...   \n",
       "\n",
       "                                         translation  \n",
       "0  Approval of opening on these establishments wi...  \n",
       "1  Wang Fengyuan spoke at the launch of his new b...  \n",
       "2  \"If you're not committed to creating a culture...  \n",
       "3  However, the premise is that the multinational...  \n",
       "4  \"Before this, I was living with my ex in Knigh...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the training set of the sixth corpora\n",
    "corpora[5][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294acf0c",
   "metadata": {},
   "source": [
    "As we can notice, in each corpora the majority of the words in the top 10, most words are stopwords. \n",
    "These words will contain no semantic meaning and it will not help us. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66773bd",
   "metadata": {},
   "source": [
    "###### Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e834441",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "finnish_stopwords= set(stopwords.words('finnish'))\n",
    "chinese_stopwords= set(swordsiso('zh'))\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b73c9acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46a8a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 0\n",
    "updates_0_reference = clean(corpora[csen][\"reference\"],finnish_stopwords, lemmatize = True, stemmer = False)\n",
    "updates_0_translation = clean(corpora[csen][\"translation\"], finnish_stopwords, lemmatize = True, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44277ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[csen], updates_0_reference, 'reference')\n",
    "update_df(corpora[csen], updates_0_translation, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df80acf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf121827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 1\n",
    "updates_1_reference = clean(corpora[deen][\"reference\"],english_stopwords,  lemmatize = True, stemmer = False)\n",
    "updates_1_translation = clean(corpora[deen][\"translation\"], english_stopwords, lemmatize = True, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12553aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[deen], updates_1_reference, 'reference')\n",
    "update_df(corpora[deen], updates_1_translation, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ab9221b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99f536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 2\n",
    "updates_2_reference = clean_finlandes(corpora[enfi][\"reference\"], english_stopwords, lemmatize = True, stemmer = False)\n",
    "updates_2_translation = clean_finlandes(corpora[enfi][\"translation\"],english_stopwords,  lemmatize = True, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c03fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[enfi], updates_2_reference, 'reference')\n",
    "update_df(corpora[enfi], updates_2_translation, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd59ae26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b360048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 3\n",
    "updates_3_reference= clean_chinese(corpora[enzh][\"reference\"],chinese_stopwords)\n",
    "updates_3_translation = clean_chinese(corpora[enzh][\"translation\"],chinese_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4080729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[enzh], updates_3_reference, 'reference')\n",
    "update_df(corpora[enzh], updates_3_translation, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f18e1be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e7bf197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 4\n",
    "updates_4_reference = clean(corpora[ruen][\"reference\"], english_stopwords, lemmatize = True, stemmer = False)\n",
    "updates_4_translation = clean(corpora[ruen][\"translation\"],english_stopwords, lemmatize = True, stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24963441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[ruen], updates_4_reference,  'reference')\n",
    "update_df(corpora[ruen], updates_4_translation, 'translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84e7b190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98fd049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the reference and translation in corpora 5\n",
    "updates_5_reference = clean_chinese(corpora[zhen][\"reference\"],english_stopwords)\n",
    "updates_5_translation = clean_chinese(corpora[zhen][\"translation\"],english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9bc64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To update the dataframe\n",
    "update_df(corpora[zhen], updates_5_reference, 'reference')\n",
    "update_df(corpora[zhen], updates_5_translation, 'translation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7cfa31",
   "metadata": {},
   "source": [
    "### Evolution Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db909103",
   "metadata": {},
   "source": [
    "#### BERT-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5857ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b3fc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation\n",
    "#transformers\n",
    "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.modeling_utils.logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529efc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf13faa6ca324c35912c0f3235f0ec7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c58472157eb424a98cac59944452fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4266863c3df40ed8edb7e9b7658256c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787ab947cbdb4ed18f1f9f1f205eec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a31af3355f427cbeb6120abf62b159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8efd9c13744338f5601dd04f121a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a775108d3aba415a8815716f4ba6d93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1729.13 seconds, 5.05 sentences/sec\n",
      "0\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaea4f3a3b24a9aa61491d62b9e8887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d805ae4d6f945299ec6a23920023722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3743.27 seconds, 7.59 sentences/sec\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373bbd1d824b413e8f4406c5249c04b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f14660fa754601ad2f54f4d1220720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52a2f255c144640af887407d3ee8a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99328caf46746f994d0cc425e5c122d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fa4b1af76b45e3b1f28af6f5a15160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacbff73a67f4e308e589ed9e4d093ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5425b033ea014e4bb6b0139aa98b783c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1631.71 seconds, 4.96 sentences/sec\n",
      "2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe37a30378e43628eee69d33814f98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a926c3fa0d514a21bb7715e380932b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06a759c514144918ff23523a2ab033d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce068b77d944690adadc66b479bb633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/269k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac9b2a1dcaa4a75bfbc1d1c25d89617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e977e4c650f46caa0f8715dc69aef31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BSP=[]\n",
    "BSR=[]\n",
    "BSF1=[]\n",
    "for i in range(len(corpus)):\n",
    "    Ptemp, Rtemp, F1temp = score(list(corpora[i].translation), list(corpora[i].reference),\\\n",
    "                                 lang=corpus[i][-2:], verbose=True)\n",
    "    #BSP.append(Ptemp)\n",
    "    #BSR.append(Rtemp)\n",
    "    BSF1.append(F1temp)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d166d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = corpora\n",
    "for i in range(len(corpora)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(BSP[i].numpy()),pd.DataFrame(BSR[i].numpy()),\\\n",
    "                          pd.DataFrame(BSF1[i].numpy())], axis=1, join='inner')\n",
    "    corpora[i].columns=['index',\"source\",\"reference\",\"translation\",\"z-score\",\"avg-score\",\"annotators\",\"BLEU\",\\\n",
    "                        \"ROUGE-1 F1-Score\",\"ROUGE-1 Precision\",\"ROUGE-1 Recall\",\"ROUGE-2 F1-Score\",\"ROUGE-2 Precision\",\\\n",
    "                        \"ROUGE-2 Recall\",\"ROUGE-L F1-Score\",\"ROUGE-L Precision\",\"ROUGE-L Recall\",\\\n",
    "                        \"WMDistance\",\"BERT-Score Precision\",\"BERT-Score Recall\",\"BERT-Score F1-Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a backup-point for corpora\n",
    "for i in range(len(corpus)):\n",
    "    corpora[i].to_excel('bckcorpora/'+corpus[i]+'.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769eb41",
   "metadata": {},
   "source": [
    "#### BLEURT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2afc4",
   "metadata": {},
   "source": [
    "Refer to https://github.com/google-research/bleurt for bleurt installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd78f9",
   "metadata": {},
   "source": [
    "<p>After installed locate scorer.py on the packages folder and typecast your tf.constants on the predict method:</p>\n",
    "<p>def predict(self, input_dict):<br>&nbsp;&nbsp;&nbsp;predictions = self._bleurt_model_ops(input_ids=tf.constant(input_dict[\"input_ids\"]<b>,dtype='int64'</b>),<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input_mask=tf.constant(input_dict[\"input_mask\"]<b>,dtype='int64'</b>),<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;segment_ids=tf.constant(input_dict[\"segment_ids\"]<b>,dtype='int64'</b>))[\"predictions\"].numpy()<br>&nbsp;&nbsp;&nbsp;return predictions</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bleurt import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb15104",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora=[]\n",
    "\n",
    "#corpora.append(pd.read_excel('cs-en.xlsx'))\n",
    "#corpora.append(pd.read_excel('de-en.xlsx'))\n",
    "#corpora.append(pd.read_excel('en-fi.xlsx'))\n",
    "#corpora.append(pd.read_excel('en-zh.xlsx'))\n",
    "#corpora.append(pd.read_excel('ru-en.xlsx'))\n",
    "#corpora.append(pd.read_excel('zh-en.xlsx'))\n",
    "\n",
    "\n",
    "        \n",
    "print('\\033[1m',len(corpora),'\\033[0mcorpora imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed075aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a backup-point for corpora\n",
    "#for i in range(len(corpus)):\n",
    "#    corpora[i].read_excel('bckcorpora/'+corpus[i]+'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fced34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dowload base \n",
    "if not(os.path.isfile('bleurt-base-128/vocab.txt')):\n",
    "    if not(os.path.isfile('https://storage.googleapis.com/bleurt-oss/bleurt-base-128.zip')):\n",
    "        urllib.request.urlretrieve(\"https://storage.googleapis.com/bleurt-oss/bleurt-base-128.zip\",\\\n",
    "                                   \"bleurt-base-128.zip\")\n",
    "    with ZipFile('bleurt-base-128.zip', 'r') as zipObj:\n",
    "        zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = \"bleurt-base-128\"\n",
    "bleurtscores=[]\n",
    "for i in tqdm(range(len(corpus))):\n",
    "    ref=corpora[i].reference.to_list()\n",
    "    can=corpora[i].translation.to_list()\n",
    "    scorer = score.BleurtScorer(checkpoint)\n",
    "    scores=scorer.score(references=ref, candidates=can)\n",
    "    bleurtscores.append(scores)\n",
    "bleurtscores[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9f799",
   "metadata": {},
   "source": [
    "#### COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = download_model(\"wmt-large-da-estimator-1719\", \"comet/\")\n",
    "model1 = download_model(\"wmt-base-da-estimator-1719\", \"comet1/\")\n",
    "model2 = download_model(\"wmt-large-hter-estimator\", \"comet2/\")\n",
    "model3 = download_model(\"wmt-base-hter-estimator\", \"comet3/\")\n",
    "model4 = download_model(\"emnlp-base-da-ranker\", \"comet4/\")\n",
    "model5 = download_model(\"wmt-large-qe-estimator-1719\", \"comet5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2276602",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores0=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores0.append(corpus_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ff759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores0[i].numpy())], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f712076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores1=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model1.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model1.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores1.append(corpus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b214531",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores1[i].numpy())], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd153826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores2=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model2.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model2.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores2.append(corpus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores2[i].numpy())], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd45d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores3=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model3.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model3.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores3.append(corpus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65eb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores3[i].numpy())], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f043a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores4=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model4.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model4.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores4.append(corpus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores4[i].numpy())], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951817a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396df91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometscores5=[]\n",
    "for i in (range(len(corpus))):\n",
    "    data = {\"src\": corpora[i].source, \"mt\": corpora[i].translation, \"ref\": corpora[i].reference}\n",
    "    data = [dict(zip(data, t)) for t in zip(*data.values())]\n",
    "    model5.predict(data, cuda=True, show_progress=True)\n",
    "    \n",
    "    _, sgm_scores = model5.predict(data, cuda=True, show_progress=False)\n",
    "    corpus_score = sum(sgm_scores)/len(sgm_scores)\n",
    "    \n",
    "    cometscores5.append(corpus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpora[i]=pd.concat([corpora[i],pd.DataFrame(cometscores5[i].numpy())], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3401f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list to keep correlations of WMDistance and Z-Score\n",
    "correl=[]\n",
    "KendallT=[]\n",
    "KendallP=[]\n",
    "#Clalculate the correlation of columns WMDistance and Z-Score on all corpora\n",
    "for i in range(len(corpus)):\n",
    "    correl.append(round(corpora[i]['WMDistance'].corr(corpora[i]['z-score']),2))\n",
    "    T,P=stats.kendalltau(corpora[i]['WMDistance'], corpora[i]['z-score'])\n",
    "    KendallT.append(round(T,2))\n",
    "    KendallP.append(round(P,2))\n",
    "#Create a DataFrame with the correlation calculated for each language pair\n",
    "corrWMDistance=pd.DataFrame(np.array([corpus,correl,KendallT,KendallP])).T\n",
    "#Rename the columns\n",
    "corrWMDistance.columns = ['Corpus', 'WMDistance (Pearson)','WMDistance (Kendall Tau-T)','WMDistance (Kendall Tau-P)']\n",
    "#calculate the mean of the correlations in the entire corpora\n",
    "avgPearson=corrWMDistance['WMDistance (Pearson)'].astype(float).mean()\n",
    "avgTau=corrWMDistance['WMDistance (Kendall Tau-T)'].astype(float).mean()\n",
    "avgP=corrWMDistance['WMDistance (Kendall Tau-P)'].astype(float).mean()\n",
    "corrWMDistance=corrWMDistance.append({'Corpus':'Average','WMDistance (Pearson)':round(avgPearson,2),\\\n",
    "                         'WMDistance (Kendall Tau-T)':round(avgTau,2),'WMDistance (Kendall Tau-P)':round(avgP,2)},\\\n",
    "                         ignore_index=True)\n",
    "corrWMDistance.set_index('Corpus', inplace=True)\n",
    "corrWMDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b419039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list to keep correlations of WMDistance and Z-Score\n",
    "correl=[]\n",
    "KendallT=[]\n",
    "KendallP=[]\n",
    "#Clalculate the correlation of columns WMDistance and Z-Score on all corpora\n",
    "for i in range(len(corpus)):\n",
    "    correl.append(round(corpora[i]['WMDistance'].corr(corpora[i]['z-score']),2))\n",
    "    T,P=stats.kendalltau(corpora[i]['WMDistance'], corpora[i]['z-score'])\n",
    "    KendallT.append(round(T,2))\n",
    "    KendallP.append(round(P,2))\n",
    "#Create a DataFrame with the correlation calculated for each language pair\n",
    "corrWMDistance=pd.DataFrame(np.array([corpus,correl,KendallT,KendallP])).T\n",
    "#Rename the columns\n",
    "corrWMDistance.columns = ['Corpus', 'WMDistance (Pearson)','WMDistance (Kendall Tau-T)','WMDistance (Kendall Tau-P)']\n",
    "#calculate the mean of the correlations in the entire corpora\n",
    "avgPearson=corrWMDistance['WMDistance (Pearson)'].astype(float).mean()\n",
    "avgTau=corrWMDistance['WMDistance (Kendall Tau-T)'].astype(float).mean()\n",
    "avgP=corrWMDistance['WMDistance (Kendall Tau-P)'].astype(float).mean()\n",
    "corrWMDistance=corrWMDistance.append({'Corpus':'Average','WMDistance (Pearson)':round(avgPearson,2),\\\n",
    "                         'WMDistance (Kendall Tau-T)':round(avgTau,2),'WMDistance (Kendall Tau-P)':round(avgP,2)},\\\n",
    "                         ignore_index=True)\n",
    "corrWMDistance.set_index('Corpus', inplace=True)\n",
    "corrWMDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list to keep correlations of WMDistance and Z-Score\n",
    "correl=[]\n",
    "KendallT=[]\n",
    "KendallP=[]\n",
    "#Clalculate the correlation of columns WMDistance and Z-Score on all corpora\n",
    "for i in range(len(corpus)):\n",
    "    correl.append(round(corpora[i]['WMDistance'].corr(corpora[i]['z-score']),2))\n",
    "    T,P=stats.kendalltau(corpora[i]['WMDistance'], corpora[i]['z-score'])\n",
    "    KendallT.append(round(T,2))\n",
    "    KendallP.append(round(P,2))\n",
    "#Create a DataFrame with the correlation calculated for each language pair\n",
    "corrWMDistance=pd.DataFrame(np.array([corpus,correl,KendallT,KendallP])).T\n",
    "#Rename the columns\n",
    "corrWMDistance.columns = ['Corpus', 'WMDistance (Pearson)','WMDistance (Kendall Tau-T)','WMDistance (Kendall Tau-P)']\n",
    "#calculate the mean of the correlations in the entire corpora\n",
    "avgPearson=corrWMDistance['WMDistance (Pearson)'].astype(float).mean()\n",
    "avgTau=corrWMDistance['WMDistance (Kendall Tau-T)'].astype(float).mean()\n",
    "avgP=corrWMDistance['WMDistance (Kendall Tau-P)'].astype(float).mean()\n",
    "corrWMDistance=corrWMDistance.append({'Corpus':'Average','WMDistance (Pearson)':round(avgPearson,2),\\\n",
    "                         'WMDistance (Kendall Tau-T)':round(avgTau,2),'WMDistance (Kendall Tau-P)':round(avgP,2)},\\\n",
    "                         ignore_index=True)\n",
    "corrWMDistance.set_index('Corpus', inplace=True)\n",
    "corrWMDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list to keep correlations of WMDistance and Z-Score\n",
    "correl=[]\n",
    "KendallT=[]\n",
    "KendallP=[]\n",
    "#Clalculate the correlation of columns WMDistance and Z-Score on all corpora\n",
    "for i in range(len(corpus)):\n",
    "    correl.append(round(corpora[i]['WMDistance'].corr(corpora[i]['z-score']),2))\n",
    "    T,P=stats.kendalltau(corpora[i]['WMDistance'], corpora[i]['z-score'])\n",
    "    KendallT.append(round(T,2))\n",
    "    KendallP.append(round(P,2))\n",
    "#Create a DataFrame with the correlation calculated for each language pair\n",
    "corrWMDistance=pd.DataFrame(np.array([corpus,correl,KendallT,KendallP])).T\n",
    "#Rename the columns\n",
    "corrWMDistance.columns = ['Corpus', 'WMDistance (Pearson)','WMDistance (Kendall Tau-T)','WMDistance (Kendall Tau-P)']\n",
    "#calculate the mean of the correlations in the entire corpora\n",
    "avgPearson=corrWMDistance['WMDistance (Pearson)'].astype(float).mean()\n",
    "avgTau=corrWMDistance['WMDistance (Kendall Tau-T)'].astype(float).mean()\n",
    "avgP=corrWMDistance['WMDistance (Kendall Tau-P)'].astype(float).mean()\n",
    "corrWMDistance=corrWMDistance.append({'Corpus':'Average','WMDistance (Pearson)':round(avgPearson,2),\\\n",
    "                         'WMDistance (Kendall Tau-T)':round(avgTau,2),'WMDistance (Kendall Tau-P)':round(avgP,2)},\\\n",
    "                         ignore_index=True)\n",
    "corrWMDistance.set_index('Corpus', inplace=True)\n",
    "corrWMDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty list to keep correlations of WMDistance and Z-Score\n",
    "correl=[]\n",
    "KendallT=[]\n",
    "KendallP=[]\n",
    "#Clalculate the correlation of columns WMDistance and Z-Score on all corpora\n",
    "for i in range(len(corpus)):\n",
    "    correl.append(round(corpora[i]['WMDistance'].corr(corpora[i]['z-score']),2))\n",
    "    T,P=stats.kendalltau(corpora[i]['WMDistance'], corpora[i]['z-score'])\n",
    "    KendallT.append(round(T,2))\n",
    "    KendallP.append(round(P,2))\n",
    "#Create a DataFrame with the correlation calculated for each language pair\n",
    "corrWMDistance=pd.DataFrame(np.array([corpus,correl,KendallT,KendallP])).T\n",
    "#Rename the columns\n",
    "corrWMDistance.columns = ['Corpus', 'WMDistance (Pearson)','WMDistance (Kendall Tau-T)','WMDistance (Kendall Tau-P)']\n",
    "#calculate the mean of the correlations in the entire corpora\n",
    "avgPearson=corrWMDistance['WMDistance (Pearson)'].astype(float).mean()\n",
    "avgTau=corrWMDistance['WMDistance (Kendall Tau-T)'].astype(float).mean()\n",
    "avgP=corrWMDistance['WMDistance (Kendall Tau-P)'].astype(float).mean()\n",
    "corrWMDistance=corrWMDistance.append({'Corpus':'Average','WMDistance (Pearson)':round(avgPearson,2),\\\n",
    "                         'WMDistance (Kendall Tau-T)':round(avgTau,2),'WMDistance (Kendall Tau-P)':round(avgP,2)},\\\n",
    "                         ignore_index=True)\n",
    "corrWMDistance.set_index('Corpus', inplace=True)\n",
    "corrWMDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11ca1da",
   "metadata": {},
   "source": [
    "#### METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteor import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ace57",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(meteor_score(['this is a cat'], 'non matching hypothesis'),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.random import multinomial, shuffle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from pprint import pprint\n",
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.meteor.meteor import Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(ref, hypo):\n",
    "    \"\"\"\n",
    "    ref, dictionary of reference sentences (id, sentence)\n",
    "    hypo, dictionary of hypothesis sentences (id, sentence)\n",
    "    score, dictionary of scores\n",
    "    \"\"\"\n",
    "    scorers = [\n",
    "        (Meteor(),\"METEOR\"),\n",
    "        (Cider(), \"CIDEr\")\n",
    "    ]\n",
    "    final_scores = {}\n",
    "    for scorer, method in scorers:\n",
    "        score, scores = scorer.compute_score(ref[0], hypo[0])\n",
    "        if type(score) == list:\n",
    "            for m, s in zip(method, score):\n",
    "                final_scores[m] = s\n",
    "        else:\n",
    "            final_scores[method] = score\n",
    "    return final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325602ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(corpora[0].reference,corpora[0].translation)\n",
    "score(corpora[1].reference,corpora[1].translation)\n",
    "score(corpora[2].reference,corpora[2].translation)\n",
    "score(corpora[3].reference,corpora[3].translation)\n",
    "score(corpora[4].reference,corpora[4].translation)\n",
    "score(corpora[5].reference,corpora[5].translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
